<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Emotion Explorer AR + Hand Gesture</title>

  <!-- A-Frame & AR.js -->
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar.min.js"></script>
  <!-- Styles -->
  <link href="newStyle.css" rel="stylesheet" />
  <style>
    body { margin: 0; overflow: hidden; }
    #startBtn {
      position: fixed; bottom: 90px; left: 50%;
      transform: translateX(-50%);
      background: #4CAF50; color: white;
      border: none; padding: 10px 20px;
      font-size: 18px; cursor: pointer; z-index: 1000;
    }
    #emotion-buttons {
      position: fixed; bottom: 20px; left: 50%;
      transform: translateX(-50%);
      display: flex; gap: 10px; z-index: 1000;
    }
    #emotion-buttons button {
      font-size: 24px; padding: 10px 20px;
      border-radius: 10px; border: none;
      background: lightgreen; cursor: pointer;
    }
    #current-emotion {
      position: fixed; top: 100px; left: 50%;
      transform: translateX(-50%);
      font-size: 48px; z-index: 1000;
    }
    canvas.faceapi {
      position: absolute; top: 0; left: 0;
      z-index: 1999; pointer-events: none;
    }
  </style>

</head>
<body>
  <button id="startBtn" onclick="startGame()">Start Game</button>
  <div id="emotion-buttons">
    <button onclick="checkEmotion('happy')">üòä Happy</button>
    <button onclick="checkEmotion('sad')">üò¢ Sad</button>
    <button onclick="checkEmotion('angry')">üò† Angry</button>
    <button onclick="checkEmotion('surprised')">üò≤ Surprised</button>
    <button onclick="checkEmotion('neutral')">üòê Neutral</button>
    <button onclick="checkEmotion('fearful')">üò® Fearful</button>
    <button onclick="checkEmotion('disgusted')">ü§¢ Disgusted</button>
    <button onclick="checkEmotion('contempt')">üò° Contempt</button>
  </div>
  <div id="current-emotion">ü§ñ</div>

  <!-- Webcam Section -->
  <section id="demos">
    <div id="liveView">
      <button id="webcamButton">ENABLE WEBCAM</button>
      <div style="position: relative;">
        <video id="webcam" muted playsinline width="640" height="480"></video>
        <canvas id="overlay" class="faceapi"></canvas>
        <canvas id="output_canvas" width="640" height="480" style="position:absolute;top:0;left:0;z-index:998;pointer-events:none;"></canvas>
      </div>
    </div>
  </section>

  <!-- AR Scene -->
  <a-scene>
    <a-assets>
      <a-asset-item id="dinoModel" src="./emotion_explorer_ar_starter/baby_dino/scene.gltf"></a-asset-item>
    </a-assets>
    <a-entity id="dino" gltf-model="#dinoModel" position="0 0 -2" scale="0.5 0.5 0.5" animation-mixer></a-entity>
    <a-entity camera></a-entity>
  </a-scene>

  <canvas id="AR-window" style="width: 100%; height: 100%; position: absolute; top: 0; left: 0;"></canvas>

  <!-- Logic + Emotion Detection -->
  <script type="module">
    import * as faceapi from 'https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/+esm';

    const video = document.getElementById("webcam");
    const canvas = document.getElementById("overlay");
    const emotions = ["happy", "sad", "angry", "surprised", "neutral", "fearful", "disgusted"];
    let correctEmotion = "";

    // Store emotion logs as an array of {timestamp, emotion}
    let emotionLog = [];

    function emotionToEmoji(emotion) {
      switch (emotion) {
        case "happy": return "üòä";
        case "sad": return "üò¢";
        case "angry": return "üò†";
        case "surprised": return "üò≤";
        case "neutral": return "üòê";
        case "fearful": return "üò®";
        case "disgusted": return "ü§¢";
        default: return "ü§ñ";
      }
    }

    window.startGame = function () {
      correctEmotion = emotions[Math.floor(Math.random() * emotions.length)];
      alert("What emotion is this?");
      document.getElementById("current-emotion").innerText = emotionToEmoji(correctEmotion);
    };

    window.checkEmotion = function (choice) {
      alert(choice === correctEmotion ? "Nice job! üòä" : "Oops! Try again.");
    };

    async function initEmotionDetection() {
      await faceapi.nets.tinyFaceDetector.loadFromUri('/models');
      await faceapi.nets.faceExpressionNet.loadFromUri('/models');

      const displaySize = { width: video.width, height: video.height };
      faceapi.matchDimensions(canvas, displaySize);

      setInterval(async () => {
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceExpressions();

        const resized = faceapi.resizeResults(detections, displaySize);
        canvas.getContext("2d",{ willReadFrequently: true }).clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, resized);
        faceapi.draw.drawFaceExpressions(canvas, resized);

        if (detections.length > 0) {
          const expressions = detections[0].expressions;
          const sorted = Object.entries(expressions).sort((a, b) => b[1] - a[1]);
          const detectedEmotion = sorted[0][0];
          document.getElementById("current-emotion").innerText = emotionToEmoji(detectedEmotion);
          console.log("Detected emotion:", detectedEmotion);

          // Log with timestamp
          emotionLog.push({
            time: new Date().toISOString(),
            emotion: detectedEmotion
          });
        }
      }, 1000);
    }

    document.getElementById("webcamButton").addEventListener("click", async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
        video.srcObject = stream;
        video.onloadedmetadata = () => {
          video.play();
          initEmotionDetection();
        };
      } catch (err) {
        alert("Webcam access was denied.");
        console.error(err);
      }
    });

    function saveEmotionsToCsv() {
      if (!emotionLog.length) return;
      let csvContent = "Time,Emotion\n";
      emotionLog.forEach(entry => {
        csvContent += `${entry.time},${entry.emotion}\n`;
      });

      const dateFormat = new Intl.DateTimeFormat("en-US", {
        year: "numeric",
        month: "2-digit",
        day: "2-digit",
        hour: "2-digit",
        minute: "2-digit",
        second: "2-digit",
        fractionalSecondDigits: 3,
      });
      const timestamp = dateFormat.format(new Date()).replace(/[/,:]/g, "-");
      const filename = `emotions_${timestamp}.csv`;

      const blob = new Blob([csvContent], { type: "text/csv" });
      const link = document.createElement("a");
      link.href = URL.createObjectURL(blob);
      link.download = filename;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
      console.log("Saved data to file: " + filename);
    }

  function uploadEmotionsToServer() {
  if (!emotionLog.length) return;
  fetch('https://cleanmeai.com/save_emotion.php', { // <-- use your real URL
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(emotionLog)
  })
  .then(response => response.text())
  .then(data => {
    console.log('Server response:', data);
  })
  .catch(error => {
    console.error('Error uploading emotions:', error);
  });
}

// Save to server when the page is closed or reloaded
    window.addEventListener("beforeunload", uploadEmotionsToServer);

    // Save CSV when the page is closed or reloaded
    window.addEventListener("beforeunload", saveEmotionsToCsv);

    window.onload = startGame;
  </script>

  <!-- Gesture Detection & Drawing -->
  <script type="module" src="./emotion_explorer_ar_starter/gestureDetection.js"></script>
  <script type="module" src="./emotion_explorer_ar_starter/faceDetection.js"></script>
  <script type="module" src="./emotion_explorer_ar_starter/draw.js"></script>
</body>
</html>